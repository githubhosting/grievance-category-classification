{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-27T18:45:17.971159400Z",
     "start_time": "2024-01-27T18:45:14.370343200Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json('test/new_dataset.json')"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 63622 entries, 0 to 63621\n",
      "Data columns (total 8 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   CategoryV7               63622 non-null  int64 \n",
      " 1   remarks_text             53566 non-null  object\n",
      " 2   subject_content_text     63622 non-null  object\n",
      " 3   root_category_name       63622 non-null  object\n",
      " 4   root_category_code       63622 non-null  int64 \n",
      " 5   total_no_of_stages       63622 non-null  int64 \n",
      " 6   hierarchy_order          63622 non-null  object\n",
      " 7   category_hierarchy_code  63622 non-null  object\n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 4.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T18:45:18.022902400Z",
     "start_time": "2024-01-27T18:45:17.972238300Z"
    }
   },
   "id": "cf1631074371f213",
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def remove_first_line(text):\n",
    "    lines = text.splitlines()\n",
    "    new_text = '\\r\\n'.join(lines[1:])\n",
    "    return new_text\n",
    "df['subject_content_text'] = df['subject_content_text'].apply(lambda x: remove_first_line(x))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T18:45:18.311013100Z",
     "start_time": "2024-01-27T18:45:18.018214200Z"
    }
   },
   "id": "70a188d242572918",
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df['subject_content_text']\n",
    "y = df['root_category_code']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T18:45:20.194844300Z",
     "start_time": "2024-01-27T18:45:18.315512Z"
    }
   },
   "id": "41068bc525297cab",
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T18:45:29.310150700Z",
     "start_time": "2024-01-27T18:45:20.198232Z"
    }
   },
   "id": "e091d8b9151a855",
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shravan\\PycharmProjects\\GrievancePortal Project\\.venv\\Lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8485658153241651\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.97      0.96      0.96       777\n",
      "          61       0.94      0.93      0.93       780\n",
      "         251       0.92      0.96      0.94      1288\n",
      "         353       0.91      0.96      0.93       207\n",
      "         398       0.74      0.71      0.73        86\n",
      "         616       0.98      0.98      0.98       241\n",
      "         656       0.62      0.63      0.63       247\n",
      "        1221       0.94      0.85      0.90       156\n",
      "        1341       0.90      0.91      0.91       126\n",
      "        1442       0.88      0.88      0.88        91\n",
      "        2113       0.88      0.96      0.92       112\n",
      "        2173       0.96      0.97      0.96      2045\n",
      "        2426       0.72      0.73      0.73       244\n",
      "        2565       0.97      0.99      0.98       427\n",
      "        2570       0.70      0.77      0.74       324\n",
      "        4414       0.98      0.99      0.98      1194\n",
      "        4465       0.85      0.95      0.90        98\n",
      "        4622       0.68      0.57      0.62        44\n",
      "        4742       0.53      0.61      0.57       270\n",
      "        4976       0.65      0.68      0.66       168\n",
      "        5256       0.29      0.28      0.28       148\n",
      "        5293       0.92      0.83      0.87       119\n",
      "        5409       0.44      0.43      0.43       183\n",
      "        5410       0.54      0.36      0.43        53\n",
      "        5587       0.57      0.19      0.29        21\n",
      "        5597       0.90      0.81      0.85        47\n",
      "        5606       0.81      0.74      0.77        53\n",
      "        6249       0.25      0.07      0.11        15\n",
      "        6251       0.86      0.55      0.67        11\n",
      "        6253       0.37      0.22      0.28        50\n",
      "        6277       0.60      0.60      0.60        10\n",
      "        6281       0.96      0.83      0.89        53\n",
      "        6296       0.56      0.50      0.53        10\n",
      "        6300       0.60      0.51      0.55        89\n",
      "        6688       1.00      0.00      0.00         1\n",
      "        6720       0.25      0.11      0.15         9\n",
      "        6748       0.00      0.00      0.00         8\n",
      "        7078       1.00      0.00      0.00         9\n",
      "        7185       1.00      1.00      1.00         9\n",
      "        7236       0.00      0.00      0.00         2\n",
      "        7263       0.71      0.57      0.63        21\n",
      "        7330       0.82      0.94      0.88       186\n",
      "        8030       0.33      0.20      0.25         5\n",
      "        8327       0.50      0.25      0.33         8\n",
      "        8451       0.67      0.29      0.40         7\n",
      "        9575       1.00      0.33      0.50         3\n",
      "        9617       0.00      0.00      0.00         2\n",
      "        9625       1.00      0.17      0.29         6\n",
      "        9675       0.94      0.94      0.94        32\n",
      "       10021       0.86      0.71      0.77        34\n",
      "       10042       1.00      0.64      0.78        11\n",
      "       10144       0.40      0.32      0.36        87\n",
      "       10607       0.67      0.40      0.50         5\n",
      "       10667       0.33      0.50      0.40         2\n",
      "       10956       0.80      0.80      0.80         5\n",
      "       11533       0.43      0.23      0.30        26\n",
      "       11555       0.36      0.17      0.23        24\n",
      "       11883       0.50      0.07      0.12        14\n",
      "       11908       1.00      0.00      0.00         3\n",
      "       12032       0.50      0.11      0.18        18\n",
      "       12384       1.00      0.11      0.20         9\n",
      "       14035       1.00      0.78      0.88         9\n",
      "       14695       1.00      0.17      0.29         6\n",
      "       15481       0.31      0.21      0.25        70\n",
      "       15527       0.38      0.16      0.22        19\n",
      "       15565       0.38      0.25      0.30        12\n",
      "       15679       0.93      0.68      0.79        19\n",
      "       15739       0.56      0.42      0.48        33\n",
      "       15793       1.00      0.00      0.00         1\n",
      "       15917       0.46      0.43      0.45        30\n",
      "       15992       1.00      0.00      0.00         6\n",
      "       16073       1.00      0.00      0.00         3\n",
      "       16115       0.00      0.00      0.00         4\n",
      "       20198       0.46      0.29      0.35        21\n",
      "       20272       0.95      0.88      0.91       169\n",
      "       20525       0.00      0.00      0.00         2\n",
      "       20754       0.93      0.93      0.93       134\n",
      "       21018       0.24      0.16      0.19        31\n",
      "       21022       0.38      0.46      0.41        13\n",
      "       22204       0.55      0.46      0.50        48\n",
      "       22384       0.85      0.97      0.91      1207\n",
      "       22504       0.00      0.00      0.00         1\n",
      "       22550       1.00      0.50      0.67         8\n",
      "       22685       1.00      0.00      0.00         5\n",
      "       22801       0.67      0.22      0.33         9\n",
      "       23375       0.83      0.95      0.88        40\n",
      "       25037       0.67      0.54      0.60        61\n",
      "       25808       0.49      0.47      0.48       423\n",
      "       26344       0.80      0.50      0.62         8\n",
      "\n",
      "    accuracy                           0.85     12725\n",
      "   macro avg       0.68      0.49      0.51     12725\n",
      "weighted avg       0.84      0.85      0.84     12725\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "model = LinearSVC(random_state=42)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, zero_division=1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T18:52:10.104306900Z",
     "start_time": "2024-01-27T18:51:55.639144600Z"
    }
   },
   "id": "afa5125795377538",
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttest-mlogloss:1.50497\n",
      "[1]\ttest-mlogloss:2.78759\n",
      "[2]\ttest-mlogloss:3.49065\n",
      "[3]\ttest-mlogloss:6.46110\n",
      "[4]\ttest-mlogloss:5.95866\n",
      "[5]\ttest-mlogloss:7.42129\n",
      "[6]\ttest-mlogloss:6.53571\n",
      "[7]\ttest-mlogloss:6.40089\n",
      "[8]\ttest-mlogloss:8.03281\n",
      "[9]\ttest-mlogloss:6.87394\n",
      "Accuracy: 60.33%\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      0.88      0.91       777\n",
      "          61       0.77      0.73      0.75       780\n",
      "         251       0.89      0.80      0.84      1288\n",
      "         353       0.89      0.75      0.81       207\n",
      "         398       0.33      0.28      0.30        86\n",
      "         616       0.96      0.91      0.94       241\n",
      "         656       0.08      0.46      0.14       247\n",
      "        1221       0.68      0.81      0.74       156\n",
      "        1341       0.84      0.81      0.82       126\n",
      "        1442       0.57      0.56      0.57        91\n",
      "        2113       0.94      0.79      0.85       112\n",
      "        2173       0.94      0.78      0.85      2045\n",
      "        2426       0.65      0.46      0.54       244\n",
      "        2565       0.95      0.95      0.95       427\n",
      "        2570       0.62      0.59      0.61       324\n",
      "        4414       0.93      0.87      0.90      1194\n",
      "        4465       0.96      0.83      0.89        98\n",
      "        4622       0.30      0.41      0.35        44\n",
      "        4742       0.28      0.33      0.30       270\n",
      "        4976       0.24      0.40      0.30       168\n",
      "        5256       0.23      0.14      0.17       148\n",
      "        5293       0.79      0.61      0.69       119\n",
      "        5409       0.41      0.21      0.28       183\n",
      "        5410       0.07      0.11      0.09        53\n",
      "        5587       0.00      0.00      0.00        21\n",
      "        5597       0.91      0.64      0.75        47\n",
      "        5606       0.97      0.55      0.70        53\n",
      "        6249       0.00      0.00      0.00        15\n",
      "        6251       1.00      0.18      0.31        11\n",
      "        6253       0.05      0.04      0.04        50\n",
      "        6277       1.00      0.50      0.67        10\n",
      "        6281       0.38      0.40      0.39        53\n",
      "        6296       1.00      0.30      0.46        10\n",
      "        6300       0.52      0.30      0.38        89\n",
      "        6688       0.00      0.00      0.00         1\n",
      "        6720       0.00      0.00      0.00         9\n",
      "        6748       0.00      0.00      0.00         8\n",
      "        7078       0.00      0.00      0.00         9\n",
      "        7185       0.88      0.78      0.82         9\n",
      "        7236       0.00      0.00      0.00         2\n",
      "        7263       1.00      0.19      0.32        21\n",
      "        7330       0.65      0.77      0.71       186\n",
      "        8030       1.00      0.20      0.33         5\n",
      "        8327       0.25      0.25      0.25         8\n",
      "        8451       1.00      0.14      0.25         7\n",
      "        9575       0.00      0.00      0.00         3\n",
      "        9617       0.00      0.00      0.00         2\n",
      "        9625       0.00      0.00      0.00         6\n",
      "        9675       0.01      0.06      0.02        32\n",
      "       10021       0.50      0.03      0.06        34\n",
      "       10042       0.33      0.18      0.24        11\n",
      "       10144       0.13      0.14      0.14        87\n",
      "       10607       0.40      0.40      0.40         5\n",
      "       10667       1.00      1.00      1.00         2\n",
      "       10956       0.75      0.60      0.67         5\n",
      "       11533       0.27      0.12      0.16        26\n",
      "       11555       0.17      0.04      0.07        24\n",
      "       11883       0.00      0.00      0.00        14\n",
      "       11908       0.00      0.00      0.00         3\n",
      "       12032       0.25      0.06      0.09        18\n",
      "       12384       0.00      0.00      0.00         9\n",
      "       14035       1.00      0.11      0.20         9\n",
      "       14695       0.50      0.17      0.25         6\n",
      "       15481       0.20      0.14      0.17        70\n",
      "       15527       0.25      0.11      0.15        19\n",
      "       15565       1.00      0.33      0.50        12\n",
      "       15679       0.73      0.58      0.65        19\n",
      "       15739       0.22      0.12      0.16        33\n",
      "       15793       0.00      0.00      0.00         1\n",
      "       15917       0.30      0.30      0.30        30\n",
      "       15992       1.00      0.17      0.29         6\n",
      "       16073       0.00      0.00      0.00         3\n",
      "       16115       0.00      0.00      0.00         4\n",
      "       20198       0.56      0.24      0.33        21\n",
      "       20272       0.75      0.87      0.80       169\n",
      "       20525       0.00      0.00      0.00         2\n",
      "       20754       0.78      0.73      0.75       134\n",
      "       21018       0.00      0.00      0.00        31\n",
      "       21022       0.29      0.15      0.20        13\n",
      "       22204       0.31      0.23      0.27        48\n",
      "       22384       0.41      0.14      0.21      1207\n",
      "       22504       0.00      0.00      0.00         1\n",
      "       22550       0.00      0.00      0.00         8\n",
      "       22685       0.00      0.00      0.00         5\n",
      "       22801       0.67      0.22      0.33         9\n",
      "       23375       0.57      0.42      0.49        40\n",
      "       25037       0.27      0.30      0.28        61\n",
      "       25808       0.14      0.35      0.20       423\n",
      "       26344       1.00      0.25      0.40         8\n",
      "\n",
      "    accuracy                           0.62     12725\n",
      "   macro avg       0.46      0.32      0.35     12725\n",
      "weighted avg       0.70      0.62      0.64     12725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shravan\\PycharmProjects\\GrievancePortal Project\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Shravan\\PycharmProjects\\GrievancePortal Project\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Shravan\\PycharmProjects\\GrievancePortal Project\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# XGBoost works with DMatrix data structure, so we need to convert our datasets\n",
    "dtrain = xgb.DMatrix(X_train_tfidf, label=LabelEncoder().fit_transform(y_train))\n",
    "dtest = xgb.DMatrix(X_test_tfidf, label=LabelEncoder().fit_transform(y_test))\n",
    "\n",
    "# Set XGBoost parameters\n",
    "# You might want to tune these parameters, especially 'max_depth' and 'eta'\n",
    "params = {\n",
    "    'objective': 'multi:softmax',  # Use softmax for multi-class classification\n",
    "    'num_class': len(y_train.unique()),  # Number of unique classes\n",
    "    'max_depth': 6,  # Depth of the trees in the boosting process\n",
    "    'eta': 0.4,  # Learning rate\n",
    "    'eval_metric': 'mlogloss',  # Evaluation metrics for validation data\n",
    "    'verbosity': 1  # Verbosity of printing messages. 1 means it prints all messages\n",
    "}\n",
    "\n",
    "# Number of boosting rounds\n",
    "num_boost_round = 100\n",
    "\n",
    "# Train the model\n",
    "bst = xgb.train(params, dtrain, num_boost_round, evals=[(dtest, 'test')], early_stopping_rounds=10)\n",
    "\n",
    "# Predictions\n",
    "y_pred = bst.predict(dtest)\n",
    "y_pred = [round(value) for value in y_pred]  # Round predictions to the nearest integer\n",
    "\n",
    "# Decode the predicted labels back to original class names\n",
    "label_decoder = LabelEncoder().fit(y_train)\n",
    "y_pred_labels = label_decoder.inverse_transform(y_pred)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(LabelEncoder().fit_transform(y_test), y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_labels))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T18:55:55.927243Z",
     "start_time": "2024-01-27T18:52:24.939454300Z"
    }
   },
   "id": "15e93e39eec3a9a2",
   "execution_count": 60
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
